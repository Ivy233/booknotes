# 优化程序性能
### 5.1 指针
有些程序是非常奇葩的。比如
```C++
void twiddle1(long *xp,long *yp)
{
    *xp+=*yp;
    *xp+=*yp;
}
```
这段程序对于xp!=yp的情况可以被解析成*xp+=2**yp。但是对于xp==yp的情况，会被解析成xp<<=2。由于无法预知这个函数会被怎么调用，或者预知的消耗太大了，编译器无法优化成任何一种，只能鸳鸯写着。
某些情况下可以使用inline，编译器可以优化，或者开-O1自动优化。
```C++
inline long f(){
    return count++;
}
```
不过请注意，inline只是建议编译器进行内联优化，正如register是建议编译器把这个变量放在寄存器里面。
### 5.2
在这里定义了一个CPE，就是每条指令需要的时钟周期数，如果你正在看《计算机组成与设计：硬件/软件接口》，那本书的CPI就是这里的CPE。在不同的程序下CPE一般不同，甚至不同平台下CPE都会有略微的差异（当然，Core i7拿到Core i5或者Xeon E3下是差不多的，如果Core i7换到ARM下会有较大差异），这是因为处理器的并行能力，代码的并行程度，从内存中读取内容的次数和利用率都不一样。
### 5.3
第一个优化方法就是开编译器自带的O1或者O2，当然O2性能更好一点，有的时候只是一点而已，大部分时候还是有差距的。
### 5.4
如果循环中的终止条件和递增变量是一个函数，而且函数的值不会受到循环体的影响，建议把其中的函数提取出来。举个最简单的例子：
```C++
for(int i = 0; i < strlen(s); i++)
{

}
```
strlen(s)是一个线性时间复杂度的函数，放在循环中无谓的将复杂度从线性变成了平方级。这是因为大部分情况下编译器无法从循环体中发现strlen是否是一个定值，如果发现了，肯定会从中提取出来的，但是不要指望这个运气。
### 5.5
减少循环中的过程调用一般也可以优化性能，因为函数调用会有大量的时间用来跳转，曾经做过实验，大概20%的差距。不过O1和O2可以优化大部分。
### 5.6
前面的优化看起来挺有意思的，那么这个在我看的时候让我瞠目结舌。
先上两段代码（CS:APP的源代码）：
```C++
void combine(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);
    *dest = IDENT;
    for (i = 0; i < length; i++)
    {
        *dest = *dest OP data[i];
    }
}
```
```C++
void combine(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);
    data_t acc = IDENT;
    for (i = 0; i < length; i++)
    {
        acc = acc OP data[i];
    }
    *dest = acc;
}
```
这两段代码看起来差不多啊，其实速度改进差不多有三倍。为什么？看一下*dest是什么东西？内存！内存是不可能比寄存器快的。

不过在第一个combine函数开了O2优化也可以达到和第二个相同的效果。建议做一下练习5.4，要求你解释了为什么开O2要远远优秀与开O1。其实核心区别就是：开O2时候%xmm0并没有重置，而是作为一个比较长久的变量一直呆在寄存器里面。
### 5.7
想要分析并行程度，最关键的是要抓住关键路径，即耗时间最多的一条路径，然后把这条路分到别的负载上去完成优化。比如说：
```C++
double poly(double a[], double x, long degree)
{
    long i;
    double result = a[0];
    double xpwr = x;
    for (i = 1; i <= degree; i++)
    {
        result += a[i] * xwpr;
        xwpr = xwpr * x;
    }
    return result;
}
double polyh(double a[], double x, long degree)
{
    long i;
    double result = a[degree];
    for (i = degree - 1 ; i >= 0; i++)
        result = a[i] + x * result;
    return result;
}
```
实际上第一段代码要快，虽然第二段代码运行要少一句话。原因很简单：有多的浮点寄存器和运算器来处理xwpr和x的乘法，所以总时间是result和xwpr分开来算的最大值，乘法比加法大，所以是按乘法算；但是另一边只能是单线处理result，所以是乘法和加法的和。
### 5.8
循环展开是另一个优化黑科技，但是相当不好掌握，因为这需要对平台的极度熟悉，甚至于了解到有多少个运算器，这是真正的并行处理。

除了循环变量的一次性变多以外，还有将结果分批放在不同的变量里面（比如说acc0~1），然后统一计算结果。如果没有分批，也要注意运算顺序，建议尽量按照哈夫曼树的构造方式放置运算。

同时如果循环展开过度，会导致寄存器不够用，只能扔在内存里增大延迟。

分支预测是很多处理器都会做的事情，如果预测错误，会产生比正常大得多的代价（虽然预测一般比较准确）。如果真的是随机性特别大的，尽量转换成条件传送而不是条件跳转。

当然不建议过度关注可以预测的分支（比如循环的终止条件）。
### 5.14
如果测试数据足够随机，建议采用以下命令来调试：
```
linux> gcc -O2 -pg prog.c -o prog
linux> ./prog file.txt
linux> gprof prog
```
这会告诉你每一个函数花费了多少时间。但是不是很准确。